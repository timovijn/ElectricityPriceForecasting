{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load necessary packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "hex_salmon = '#F68F83'\n",
    "hex_gold = '#BC9661'\n",
    "hex_indigo = '#2D2E5F'\n",
    "hex_maroon = '#8C4750'\n",
    "hex_white = '#FAFAFA'\n",
    "hex_blue = '#7EB5D2'\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as dates\n",
    "\n",
    "import matplotlib.font_manager as font_manager\n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "mpl.rcParams['font.family'] = 'SF Mono'\n",
    "mpl.rcParams['font.weight'] = 'medium'\n",
    "mpl.rcParams['axes.titleweight'] = 'semibold'\n",
    "mpl.rcParams['axes.labelweight'] = 'medium'\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[hex_indigo, hex_salmon, hex_maroon])\n",
    "mpl.rcParams[\"figure.titlesize\"] = 'large'\n",
    "mpl.rcParams[\"figure.titleweight\"] = 'semibold'\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from entsoe import EntsoePandasClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle(f\"./features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = features[['ID3']]\n",
    "outputs = features[['ID3']]\n",
    "\n",
    "inputs_train = inputs[inputs.index.year < 2018]\n",
    "outputs_train = outputs[outputs.index.year < 2018]\n",
    "\n",
    "inputs_test = inputs[inputs.index.year == 2018]\n",
    "outputs_test = outputs[outputs.index.year == 2018]\n",
    "\n",
    "# Scale inputs\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "inputs_train = pd.DataFrame(scaler.fit_transform(inputs_train), columns = inputs_train.columns)\n",
    "inputs_test = pd.DataFrame(scaler.transform(inputs_test), columns = inputs_test.columns)\n",
    "\n",
    "time_steps = 6\n",
    "for_periods = 1\n",
    "lag = 4\n",
    "\n",
    "# X_train and y_train\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(0, len(outputs_train)-time_steps-lag+1):\n",
    "    for ii in range(0, time_steps):\n",
    "        X_train.extend(inputs_train.iloc[i+ii].to_numpy())\n",
    "    y_train.extend(outputs_train.iloc[i+time_steps+lag-1].to_numpy())\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "X_train = X_train.reshape(y_train.shape[0], time_steps, inputs.shape[1])\n",
    "\n",
    "# X_test and y_test\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(0, len(outputs_test)-time_steps-lag+1):\n",
    "    for ii in range(0, time_steps):\n",
    "        X_test.extend(inputs_test.iloc[i+ii].to_numpy())\n",
    "    y_test.extend(outputs_test.iloc[i+time_steps+lag-1].to_numpy())\n",
    "\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "X_test = X_test.reshape(y_test.shape[0], time_steps, inputs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train, y_train, X_test, scaler):\n",
    "    # create a model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "    from keras.optimizers import SGD, Adam\n",
    "    \n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(units = 200, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2]), activation = 'tanh'))\n",
    "    model_lstm.add(LSTM(units = 100, return_sequences = True))\n",
    "    model_lstm.add(LSTM(units = 50, return_sequences = False))\n",
    "    \n",
    "    model_lstm.add(Dense(units = 1, activation = 'linear'))\n",
    "\n",
    "    optimizer = Adam(clipvalue = 0.5)\n",
    "    # model_lstm.compile(loss = 'mse', optimizer=optimizer)\n",
    "\n",
    "    # Compiling\n",
    "    model_lstm.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    # Fitting to the training set\n",
    "    history = model_lstm.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 50, batch_size = 16, verbose = 1)\n",
    "\n",
    "    LSTM_prediction = model_lstm.predict(X_test)\n",
    "    # LSTM_prediction = scaler.inverse_transform(LSTM_prediction)\n",
    "\n",
    "    # self.model = model_lstm\n",
    "\n",
    "    return model_lstm, LSTM_prediction, history\n",
    "\n",
    "my_LSTM_model, LSTM_prediction, history = LSTM_model(X_train, y_train, X_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(preds):\n",
    "\n",
    "    actual_pred = pd.DataFrame()\n",
    "\n",
    "    # mask = (ID3.index.year == 2018) \n",
    "    actual_pred['Actual'] = y_test\n",
    "    actual_pred['Predicted'] = preds[:, 0]\n",
    "\n",
    "    from keras.metrics import MeanSquaredError\n",
    "    m = MeanSquaredError()\n",
    "    actual_pred['Actual'] = actual_pred['Actual'].astype(int)\n",
    "    actual_pred['Predicted'] = actual_pred['Predicted'].astype(int)\n",
    "    m.update_state(np.array(actual_pred['Actual']), np.array(actual_pred['Predicted']))\n",
    "    \n",
    "    return (m.result().numpy(), actual_pred)\n",
    "\n",
    "m, prediction = actual_pred_plot(LSTM_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# Pre\n",
    "\n",
    "actual_pred = prediction\n",
    "\n",
    "# actual_pred = pd.DataFrame()\n",
    "\n",
    "# actual_pred['Actual'] = features['ID3'][0:len(prediction)]\n",
    "# actual_pred['Predicted'] = prediction[:, 0]\n",
    "\n",
    "####################################################################################################\n",
    "# Plot 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10 ,5))\n",
    "\n",
    "x, y = actual_pred.index, actual_pred['Actual']\n",
    "\n",
    "ax.plot(x, y)\n",
    "\n",
    "####################################################################################################\n",
    "# Plot 2\n",
    "\n",
    "x, y = actual_pred.index, actual_pred['Predicted']\n",
    "\n",
    "ax.plot(x, y, alpha = 0.5)\n",
    "\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "\n",
    "smape(actual_pred['Actual'], actual_pred['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.history.keys():\n",
    "    plt.plot(history.history[key],label=key)\n",
    "plt.title(\"loss={:5.4f}\".format(hist.history[\"loss\"][-1]))\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  }
 ]
}