{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load necessary packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "hex_salmon = '#F68F83'\n",
    "hex_gold = '#BC9661'\n",
    "hex_indigo = '#2D2E5F'\n",
    "hex_maroon = '#8C4750'\n",
    "hex_white = '#FAFAFA'\n",
    "hex_blue = '#7EB5D2'\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as dates\n",
    "\n",
    "import matplotlib.font_manager as font_manager\n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "mpl.rcParams['font.family'] = 'SF Mono'\n",
    "mpl.rcParams['font.weight'] = 'medium'\n",
    "mpl.rcParams['axes.titleweight'] = 'semibold'\n",
    "mpl.rcParams['axes.labelweight'] = 'medium'\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[hex_indigo, hex_salmon, hex_maroon])\n",
    "mpl.rcParams[\"figure.titlesize\"] = 'large'\n",
    "mpl.rcParams[\"figure.titleweight\"] = 'semibold'\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from entsoe import EntsoePandasClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle(f\"./features.pkl\")\n",
    "\n",
    "ID3 = pd.DataFrame()\n",
    "\n",
    "ID3['ID3'] = features['ID3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2015-01-01 05:00:00+00:00    27.500000\n",
       "2015-01-01 06:00:00+00:00    26.780822\n",
       "2015-01-01 07:00:00+00:00    25.852273\n",
       "2015-01-01 08:00:00+00:00    24.400000\n",
       "2015-01-01 09:00:00+00:00    25.625000\n",
       "                               ...    \n",
       "2018-12-21 23:00:00+00:00    50.911996\n",
       "2018-12-22 00:00:00+00:00    53.554378\n",
       "2018-12-22 01:00:00+00:00    53.716854\n",
       "2018-12-22 02:00:00+00:00    52.950763\n",
       "2018-12-22 03:00:00+00:00    53.277543\n",
       "Name: ID3, Length: 33845, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "ID3['ID3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                 ID3    VOL    MCP      LOAD    LOAD_F  \\\n",
       "2018-12-21 23:00:00+00:00  50.911996  499.5  50.63  11756.25  12950.00   \n",
       "2018-12-22 00:00:00+00:00  53.554378  309.1  53.07  11164.25  12318.00   \n",
       "2018-12-22 01:00:00+00:00  53.716854  438.8  48.50  10796.75  11741.50   \n",
       "2018-12-22 02:00:00+00:00  52.950763  294.6  46.54  10626.25  11420.75   \n",
       "2018-12-22 03:00:00+00:00  53.277543  439.2  39.50  10685.50  11313.00   \n",
       "\n",
       "                           LOAD_FE   ID3 (-4)   ID3 (-5)   ID3 (-6)  \\\n",
       "2018-12-21 23:00:00+00:00  1193.75  53.277543  53.479330  54.977402   \n",
       "2018-12-22 00:00:00+00:00  1153.75  53.479330  54.977402  57.227163   \n",
       "2018-12-22 01:00:00+00:00   944.75  54.977402  57.227163  57.961460   \n",
       "2018-12-22 02:00:00+00:00   794.50  57.227163  57.961460  58.304843   \n",
       "2018-12-22 03:00:00+00:00   627.50  57.961460  58.304843  57.755109   \n",
       "\n",
       "                            ID3 (-7)  ...  HOD 14  HOD 15  HOD 16  HOD 17  \\\n",
       "2018-12-21 23:00:00+00:00  57.227163  ...       0       0       0       0   \n",
       "2018-12-22 00:00:00+00:00  57.961460  ...       0       0       0       0   \n",
       "2018-12-22 01:00:00+00:00  58.304843  ...       0       0       0       0   \n",
       "2018-12-22 02:00:00+00:00  57.755109  ...       0       0       0       0   \n",
       "2018-12-22 03:00:00+00:00  57.734450  ...       0       0       0       0   \n",
       "\n",
       "                           HOD 18  HOD 19  HOD 20  HOD 21  HOD 22  HOD 23  \n",
       "2018-12-21 23:00:00+00:00       0       0       0       0       0       1  \n",
       "2018-12-22 00:00:00+00:00       0       0       0       0       0       0  \n",
       "2018-12-22 01:00:00+00:00       0       0       0       0       0       0  \n",
       "2018-12-22 02:00:00+00:00       0       0       0       0       0       0  \n",
       "2018-12-22 03:00:00+00:00       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 237 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID3</th>\n      <th>VOL</th>\n      <th>MCP</th>\n      <th>LOAD</th>\n      <th>LOAD_F</th>\n      <th>LOAD_FE</th>\n      <th>ID3 (-4)</th>\n      <th>ID3 (-5)</th>\n      <th>ID3 (-6)</th>\n      <th>ID3 (-7)</th>\n      <th>...</th>\n      <th>HOD 14</th>\n      <th>HOD 15</th>\n      <th>HOD 16</th>\n      <th>HOD 17</th>\n      <th>HOD 18</th>\n      <th>HOD 19</th>\n      <th>HOD 20</th>\n      <th>HOD 21</th>\n      <th>HOD 22</th>\n      <th>HOD 23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-12-21 23:00:00+00:00</th>\n      <td>50.911996</td>\n      <td>499.5</td>\n      <td>50.63</td>\n      <td>11756.25</td>\n      <td>12950.00</td>\n      <td>1193.75</td>\n      <td>53.277543</td>\n      <td>53.479330</td>\n      <td>54.977402</td>\n      <td>57.227163</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2018-12-22 00:00:00+00:00</th>\n      <td>53.554378</td>\n      <td>309.1</td>\n      <td>53.07</td>\n      <td>11164.25</td>\n      <td>12318.00</td>\n      <td>1153.75</td>\n      <td>53.479330</td>\n      <td>54.977402</td>\n      <td>57.227163</td>\n      <td>57.961460</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-22 01:00:00+00:00</th>\n      <td>53.716854</td>\n      <td>438.8</td>\n      <td>48.50</td>\n      <td>10796.75</td>\n      <td>11741.50</td>\n      <td>944.75</td>\n      <td>54.977402</td>\n      <td>57.227163</td>\n      <td>57.961460</td>\n      <td>58.304843</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-22 02:00:00+00:00</th>\n      <td>52.950763</td>\n      <td>294.6</td>\n      <td>46.54</td>\n      <td>10626.25</td>\n      <td>11420.75</td>\n      <td>794.50</td>\n      <td>57.227163</td>\n      <td>57.961460</td>\n      <td>58.304843</td>\n      <td>57.755109</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-12-22 03:00:00+00:00</th>\n      <td>53.277543</td>\n      <td>439.2</td>\n      <td>39.50</td>\n      <td>10685.50</td>\n      <td>11313.00</td>\n      <td>627.50</td>\n      <td>57.961460</td>\n      <td>58.304843</td>\n      <td>57.755109</td>\n      <td>57.734450</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 237 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "features.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ts_train_test(ID3, time_steps, for_periods):\n",
    "\n",
    "#     # Create training and test sets\n",
    "#     mask = (ID3.index.year < 2018)\n",
    "#     ts_train = ID3.loc[mask]['ID3'].values\n",
    "#     ts_train = ts_train.reshape(1, -1).transpose()\n",
    "\n",
    "#     mask = (ID3.index.year == 2018)\n",
    "#     ts_test = ID3.loc[mask]['ID3'].values\n",
    "#     ts_test = ts_test.reshape(1, -1).transpose()\n",
    "\n",
    "#     # ts_train = ID3[:'2018'].iloc['ID3'].values\n",
    "#     # ts_test  = ID3['2019':].iloc['ID3'].values\n",
    "\n",
    "#     # Scale the data\n",
    "#     from sklearn.preprocessing import MinMaxScaler\n",
    "#     sc = MinMaxScaler(feature_range=(0,1))\n",
    "#     ts_train_unscaled = ts_train\n",
    "#     ts_train = sc.fit_transform(ts_train)\n",
    "\n",
    "#     # Create training data of s samples and t time steps\n",
    "#     X_train = []\n",
    "#     y_train = []\n",
    "#     y_train_stacked = []\n",
    "    \n",
    "#     for i in range(time_steps, len(ts_train)-1): \n",
    "#         X_train.append(ts_train[i-time_steps:i,0])\n",
    "#         y_train.append(ts_train[i:i+for_periods,0])\n",
    "#     X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "#     # Reshape X_train for efficient modelling\n",
    "#     X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "#     # Prepare to create X_test\n",
    "#     inputs = pd.concat((ID3['ID3'][:'2018'], ID3['ID3']['2019':]),axis=0).values\n",
    "#     inputs = inputs[len(inputs)-len(ts_test) - time_steps:]\n",
    "#     inputs = inputs.reshape(-1,1)\n",
    "#     inputs  = sc.transform(inputs)\n",
    "\n",
    "#     X_test = []\n",
    "#     for i in range(time_steps, len(ts_test)+time_steps-for_periods):\n",
    "#         X_test.append(inputs[i-time_steps:i,0])\n",
    "        \n",
    "#     X_test = np.array(X_test)\n",
    "#     X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "#     return X_train, y_train , X_test, sc\n",
    "\n",
    "# ##########################################################################\n",
    "# X_train, y_train, X_test, sc = ts_train_test(ID3, 5, 2)\n",
    "# ##########################################################################\n",
    "\n",
    "# X_train.shape[0], X_train.shape[1]\n",
    "\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.11149121 0.10957419 0.10709908 0.10322794 0.10649326]\n [0.10957419 0.10709908 0.10322794 0.10649326 0.11575613]\n [0.10709908 0.10322794 0.10649326 0.11575613 0.10844484]\n ...\n [0.17108734 0.19165164 0.17957977 0.22781275 0.25337006]\n [0.19165164 0.17957977 0.22781275 0.25337006 0.21756489]\n [0.17957977 0.22781275 0.25337006 0.21756489 0.10276111]]\n[[[0.11149121]\n  [0.10957419]\n  [0.10709908]\n  [0.10322794]\n  [0.10649326]]\n\n [[0.10957419]\n  [0.10709908]\n  [0.10322794]\n  [0.10649326]\n  [0.11575613]]\n\n [[0.10709908]\n  [0.10322794]\n  [0.10649326]\n  [0.11575613]\n  [0.10844484]]\n\n ...\n\n [[0.17108734]\n  [0.19165164]\n  [0.17957977]\n  [0.22781275]\n  [0.25337006]]\n\n [[0.19165164]\n  [0.17957977]\n  [0.22781275]\n  [0.25337006]\n  [0.21756489]]\n\n [[0.17957977]\n  [0.22781275]\n  [0.25337006]\n  [0.21756489]\n  [0.10276111]]]\n[[0.11575613 0.10844484]\n [0.10844484 0.10768885]\n [0.10768885 0.11159374]\n ...\n [0.21756489 0.10276111]\n [0.10276111 0.08860073]\n [0.08860073 0.08136801]]\n"
     ]
    }
   ],
   "source": [
    "time_steps = 5\n",
    "for_periods = 2\n",
    "\n",
    "lag = 4\n",
    "\n",
    "# Create training and test sets\n",
    "mask = (ID3.index.year < 2018)\n",
    "ts_train = ID3.loc[mask]['ID3'].values\n",
    "ts_train = ts_train.reshape(1, -1).transpose()\n",
    "\n",
    "mask = (ID3.index.year == 2018)\n",
    "ts_test = ID3.loc[mask]['ID3'].values\n",
    "ts_test = ts_test.reshape(1, -1).transpose()\n",
    "\n",
    "# Scale the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "ts_train_unscaled = ts_train\n",
    "ts_train = sc.fit_transform(ts_train)\n",
    "\n",
    "# Create training data of s samples and t time steps\n",
    "X_train = []\n",
    "y_train = []\n",
    "y_train_stacked = []\n",
    "\n",
    "for i in range(time_steps, len(ts_train)-1): \n",
    "    X_train.append(ts_train[i-time_steps:i,0])\n",
    "    y_train.append(ts_train[i:i+for_periods,0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "# Reshape X_train for efficient modelling\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Prepare to create X_test\n",
    "inputs = pd.concat((ID3['ID3'][:'2018'], ID3['ID3']['2019':]),axis=0).values\n",
    "inputs = inputs[len(inputs)-len(ts_test) - time_steps:]\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = sc.transform(inputs)\n",
    "\n",
    "X_test = []\n",
    "for i in range(time_steps, len(ts_test)+time_steps-for_periods):\n",
    "    X_test.append(inputs[i-time_steps:i,0])\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "X_train.shape[0], X_train.shape[1]\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0], X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 3-D shape of X_train to a data frame so we can see: \n",
    "X_train_see = pd.DataFrame(np.reshape(X_train, (X_train.shape[0], X_train.shape[1])))\n",
    "y_train_see = pd.DataFrame(y_train)\n",
    "pd.concat([X_train_see, y_train_see], axis=1)\n",
    "\n",
    "# Convert the 3-D shape of X_test to a data frame so we can see: \n",
    "X_test_see = pd.DataFrame(np.reshape(X_test, (X_test.shape[0], X_test.shape[1])))\n",
    "pd.DataFrame(X_test_see)\n",
    "\n",
    "print(), print(colored(f'There are {X_train.shape[0]} samples in the training data', 'green'))\n",
    "print(colored(f'There are {X_test.shape[0]} samples in the test data', 'green')), print()\n",
    "\n",
    "print(X_train_see)\n",
    "print(y_train_see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train, y_train, X_test, sc):\n",
    "    # create a model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "    from keras.optimizers import SGD, Adam\n",
    "    \n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(units = 200, return_sequences = True, input_shape=(X_train.shape[1],1), activation='tanh'))\n",
    "    model_lstm.add(LSTM(units = 100, return_sequences = True))\n",
    "    model_lstm.add(LSTM(units = 50, return_sequences = False))\n",
    "    \n",
    "    model_lstm.add(Dense(units = 1, activation='linear'))\n",
    "\n",
    "    optimizer = Adam(clipvalue=0.5)\n",
    "    # model_lstm.compile(loss = 'mse', optimizer=optimizer)\n",
    "\n",
    "    # Compiling\n",
    "    model_lstm.compile(optimizer=optimizer,loss='mean_squared_error')\n",
    "    # Fitting to the training set\n",
    "    model_lstm.fit(X_train,y_train,epochs=50,batch_size=16, verbose=5)\n",
    "\n",
    "    LSTM_prediction = model_lstm.predict(X_test)\n",
    "    LSTM_prediction = sc.inverse_transform(LSTM_prediction)\n",
    "\n",
    "    # self.model = model_lstm\n",
    "\n",
    "    return model_lstm, LSTM_prediction\n",
    "\n",
    "my_LSTM_model, LSTM_prediction = LSTM_model(X_train, y_train, X_test, sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(preds):\n",
    "\n",
    "    actual_pred = pd.DataFrame()\n",
    "\n",
    "    mask = (ID3.index.year == 2018)\n",
    "    actual_pred['Actual'] = ID3.loc[mask]['ID3'][0:len(preds)]\n",
    "    actual_pred['Predicted'] = preds[:, 0]\n",
    "\n",
    "    from keras.metrics import MeanSquaredError\n",
    "    m = MeanSquaredError()\n",
    "    actual_pred['Actual'] = actual_pred['Actual'].astype(int)\n",
    "    actual_pred['Predicted'] = actual_pred['Predicted'].astype(int)\n",
    "    m.update_state(np.array(actual_pred['Actual']), np.array(actual_pred['Predicted']))\n",
    "    \n",
    "    return (m.result().numpy(), actual_pred)\n",
    "\n",
    "m, prediction = actual_pred_plot(LSTM_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = features.drop(labels=['ID3', 'VOL', 'LOAD_F', 'LOAD_FE'], axis=1)\n",
    "# y = features['ID3']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X,\n",
    "#     y,\n",
    "#     test_size = 0.3,\n",
    "#     random_state = 0,\n",
    "#     shuffle = True)\n",
    "\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_unscaled = X_train\n",
    "# X_test_unscaled = X_test\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "\n",
    "# X_train = scaler.transform(X_train_unscaled)\n",
    "\n",
    "# X_test = scaler.transform(X_test_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def MLP_model(X_train, y_train, X_test):\n",
    "#     # create a model\n",
    "#     from keras.models import Sequential\n",
    "#     from keras.layers import Dense\n",
    "#     from keras.optimizers import SGD, Adam\n",
    "    \n",
    "#     model_MLP = Sequential()\n",
    "#     model_MLP.add(Dense(200, activation='relu', kernel_initializer='he_normal', input_shape=(X_train.shape[1],)))\n",
    "#     model_MLP.add(Dense(100, activation='relu', kernel_initializer='he_normal'))\n",
    "#     model_MLP.add(Dense(1))\n",
    "\n",
    "#     optimizer = Adam(clipvalue=0.5)\n",
    "#     # model_lstm.compile(loss = 'mse', optimizer=optimizer)\n",
    "\n",
    "#     # Compiling\n",
    "#     model_MLP.compile(optimizer=optimizer,loss='mean_squared_error')\n",
    "#     # Fitting to the training set\n",
    "#     model_MLP.fit(X_train, y_train, epochs = 50, batch_size = 16, verbose = 5)\n",
    "\n",
    "#     prediction = model_MLP.predict(X_test)\n",
    "#     # prediction = sc.inverse_transform(prediction)\n",
    "\n",
    "#     # self.model = model_lstm\n",
    "\n",
    "#     return model_MLP, prediction\n",
    "\n",
    "# model, prediction = MLP_model(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# #Step1. Define the model\n",
    "# model = Sequential()\n",
    "# model.add(Dense(16, activation = 'relu', kernel_initializer = 'he_normal', input_shape = (X_train.shape[1],)))\n",
    "# model.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal'))\n",
    "# model.add(Dense(1))\n",
    "# #Step2. Compile the model\n",
    "# model.compile(optimizer = 'adam', loss = 'mse', metrics = 'mae')\n",
    "# #Step3. Fit the model\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100,batch_size=64, verbose=5)\n",
    "# #Step4.1 Evaluate the model\n",
    "# loss, mae = model.evaluate(X_test, y_test)\n",
    "# #Step4.2 Plot the learning curve\n",
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='val')\n",
    "# plt.show()\n",
    "\n",
    "# prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual_pred = pd.DataFrame()\n",
    "\n",
    "# actual_pred['Actual'] = features['ID3'][0:len(prediction)]\n",
    "# actual_pred['Predicted'] = prediction[:, 0]\n",
    "\n",
    "# from keras.metrics import MeanSquaredError\n",
    "# m = MeanSquaredError()\n",
    "# actual_pred['Actual'] = actual_pred['Actual'].astype(int)\n",
    "# actual_pred['Predicted'] = actual_pred['Predicted'].astype(int)\n",
    "# m.update_state(np.array(actual_pred['Actual']), np.array(actual_pred['Predicted']))\n",
    "\n",
    "# x, y = actual_pred.index, actual_pred['Actual']\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (5 ,5))\n",
    "# ax.plot(x, y)\n",
    "\n",
    "# plt.xticks(rotation = 90)\n",
    "\n",
    "# x, y = actual_pred.index, actual_pred['Predicted']\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (5 ,5))\n",
    "# ax.plot(x, y)\n",
    "\n",
    "# plt.xticks(rotation = 90);\n",
    "\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# Pre\n",
    "\n",
    "actual_pred = prediction\n",
    "\n",
    "# actual_pred = pd.DataFrame()\n",
    "\n",
    "# actual_pred['Actual'] = features['ID3'][0:len(prediction)]\n",
    "# actual_pred['Predicted'] = prediction[:, 0]\n",
    "\n",
    "####################################################################################################\n",
    "# Plot 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10 ,5))\n",
    "\n",
    "x, y = actual_pred.index, actual_pred['Actual']\n",
    "\n",
    "ax.plot(x, y)\n",
    "\n",
    "####################################################################################################\n",
    "# Plot 2\n",
    "\n",
    "x, y = actual_pred.index, actual_pred['Predicted']\n",
    "\n",
    "ax.plot(x, y, alpha = 0.5)\n",
    "\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(A, F):\n",
    "    return 100/len(A) * np.sum(2 * np.abs(F - A) / (np.abs(A) + np.abs(F)))\n",
    "\n",
    "smape(actual_pred['Actual'], actual_pred['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}