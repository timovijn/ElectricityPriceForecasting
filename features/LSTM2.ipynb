{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "hex_salmon = '#F68F83'\n",
    "hex_gold = '#BC9661'\n",
    "hex_indigo = '#2D2E5F'\n",
    "hex_maroon = '#8C4750'\n",
    "hex_white = '#FAFAFA'\n",
    "hex_blue = '#7EB5D2'\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as dates\n",
    "\n",
    "import matplotlib.font_manager as font_manager\n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "mpl.rcParams['font.family'] = 'SF Mono'\n",
    "mpl.rcParams['font.weight'] = 'medium'\n",
    "mpl.rcParams['axes.titleweight'] = 'semibold'\n",
    "mpl.rcParams['axes.labelweight'] = 'medium'\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[hex_indigo, hex_salmon, hex_maroon])\n",
    "mpl.rcParams[\"figure.titlesize\"] = 'large'\n",
    "mpl.rcParams[\"figure.titleweight\"] = 'semibold'\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from entsoe import EntsoePandasClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_pickle(f\"./features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((23691, 4), (10154, 4))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "input_features = features[['ID3', 'VOL', 'MCP', 'LOAD_F']]\n",
    "output_features = features['ID3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input_features,\n",
    "    output_features,\n",
    "    test_size = 0.3,\n",
    "    random_state = 0,\n",
    "    shuffle = True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "# Scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "\n",
    "for i in X_train.columns:\n",
    "    scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "    s_s = scaler.fit_transform(X_train[i].values.reshape(-1, 1))\n",
    "    s_s = np.reshape(s_s, len(s_s))\n",
    "    scalers['scaler_'+i] = scaler\n",
    "    X_train[i] = s_s\n",
    "\n",
    "for i in X_test.columns:\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    s_s = scaler.transform(X_test[i].values.reshape(-1, 1))\n",
    "    s_s = np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+i] = scaler\n",
    "    X_test[i] = s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "  #\n",
    "  # n_past ==> no of past observations\n",
    "  #\n",
    "  # n_future ==> no of future observations \n",
    "  #\n",
    "  X, y = list(), list()\n",
    "  for window_start in range(len(series)):\n",
    "    past_end = window_start + n_past\n",
    "    future_end = past_end + n_future\n",
    "    if future_end > len(series):\n",
    "      break\n",
    "    # slicing the past and future parts of the window\n",
    "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "    X.append(past)\n",
    "    y.append(future)\n",
    "  return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_past = 10\n",
    "n_future = 5 \n",
    "n_features = 4\n",
    "\n",
    "X_train, y_train = split_series(X_train.values, n_past, n_future)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "X_test, y_test = split_series(X_test.values, n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def LSTM_model(X_train, y_train, X_test, sc):\n",
    "#     # create a model\n",
    "#     from keras.models import Sequential\n",
    "#     from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "#     from keras.optimizers import SGD, Adam\n",
    "    \n",
    "#     model_lstm = Sequential()\n",
    "#     model_lstm.add(LSTM(units = 200, return_sequences = True, input_shape=(10, 4), activation='tanh'))\n",
    "#     model_lstm.add(LSTM(units = 100, return_sequences = True))\n",
    "#     model_lstm.add(LSTM(units = 50, return_sequences = False))\n",
    "    \n",
    "#     model_lstm.add(Dense(units = 4, activation='linear'))\n",
    "\n",
    "#     optimizer = Adam(clipvalue=0.5)\n",
    "#     # model_lstm.compile(loss = 'mse', optimizer=optimizer)\n",
    "\n",
    "#     # Compiling\n",
    "#     model_lstm.compile(optimizer=optimizer,loss='mean_squared_error')\n",
    "#     # Fitting to the training set\n",
    "#     model_lstm.fit(X_train,y_train,epochs=50,batch_size=16, verbose=5)\n",
    "\n",
    "#     LSTM_prediction = model_lstm.predict(X_test)\n",
    "#     # LSTM_prediction = sc.inverse_transform(LSTM_prediction)\n",
    "\n",
    "#     # self.model = model_lstm\n",
    "\n",
    "#     return model_lstm, LSTM_prediction\n",
    "\n",
    "# my_LSTM_model, LSTM_prediction = LSTM_model(X_train, y_train, X_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 10, 4)]      0                                            \n__________________________________________________________________________________________________\nlstm (LSTM)                     [(None, 10, 100), (N 42000       input_1[0][0]                    \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 100), (None, 80400       lstm[0][0]                       \n__________________________________________________________________________________________________\nrepeat_vector (RepeatVector)    (None, 5, 100)       0           lstm_1[0][0]                     \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   (None, 5, 100)       80400       repeat_vector[0][0]              \n                                                                 lstm[0][1]                       \n                                                                 lstm[0][2]                       \n__________________________________________________________________________________________________\nlstm_3 (LSTM)                   (None, 5, 100)       80400       lstm_2[0][0]                     \n                                                                 lstm_1[0][1]                     \n                                                                 lstm_1[0][2]                     \n__________________________________________________________________________________________________\ntime_distributed (TimeDistribut (None, 5, 4)         404         lstm_3[0][0]                     \n==================================================================================================\nTotal params: 283,604\nTrainable params: 283,604\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# E2D2\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
    "#\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
    "#\n",
    "model_e2d2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "Epoch 2/25\n",
      "Epoch 3/25\n",
      "Epoch 4/25\n",
      "Epoch 5/25\n",
      "Epoch 6/25\n",
      "Epoch 7/25\n",
      "Epoch 8/25\n",
      "Epoch 9/25\n",
      "Epoch 10/25\n",
      "Epoch 11/25\n",
      "Epoch 12/25\n",
      "Epoch 13/25\n",
      "Epoch 14/25\n",
      "Epoch 15/25\n",
      "Epoch 16/25\n",
      "Epoch 17/25\n",
      "Epoch 18/25\n",
      "Epoch 19/25\n",
      "Epoch 20/25\n",
      "Epoch 21/25\n",
      "Epoch 22/25\n",
      "Epoch 23/25\n",
      "Epoch 24/25\n",
      "Epoch 25/25\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "# model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "# history_e1d1=model_e1d1.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])\n",
    "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=5,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_e2d2=model_e2d2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 2 with size 4",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6125d1dd26ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# pred1_e2d2[:,:,index]=scaler.inverse_transform(pred1_e2d2[:,:,index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred_e2d2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_e2d2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 2 with size 4"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(X_train)):\n",
    "    # scaler = scalers['scaler_'+i]\n",
    "    # pred1_e1d1[:,:,index]=scaler.inverse_transform(pred1_e1d1[:,:,index])\n",
    "    # pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
    "    # pred1_e2d2[:,:,index]=scaler.inverse_transform(pred1_e2d2[:,:,index])\n",
    "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "    y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
    "    y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-acaf40785eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# Pre\n",
    "\n",
    "actual_pred = prediction\n",
    "\n",
    "# actual_pred = pd.DataFrame()\n",
    "\n",
    "# actual_pred['Actual'] = features['ID3'][0:len(prediction)]\n",
    "# actual_pred['Predicted'] = prediction[:, 0]\n",
    "\n",
    "####################################################################################################\n",
    "# Plot 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10 ,5))\n",
    "\n",
    "x, y = actual_pred.index, actual_pred['Actual']\n",
    "\n",
    "ax.plot(x, y)\n",
    "\n",
    "####################################################################################################\n",
    "# Plot 2\n",
    "\n",
    "x, y = actual_pred.index, actual_pred['Predicted']\n",
    "\n",
    "ax.plot(x, y, alpha = 0.5)\n",
    "\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}