{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "hex_salmon = '#F68F83'\n",
    "hex_gold = '#BC9661'\n",
    "hex_indigo = '#2D2E5F'\n",
    "hex_maroon = '#8C4750'\n",
    "hex_white = '#FAFAFA'\n",
    "hex_blue = '#7EB5D2'\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as dates\n",
    "\n",
    "import matplotlib.font_manager as font_manager\n",
    "mpl.font_manager._rebuild()\n",
    "\n",
    "mpl.rcParams['font.family'] = 'SF Mono'\n",
    "mpl.rcParams['font.weight'] = 'medium'\n",
    "mpl.rcParams['axes.titleweight'] = 'semibold'\n",
    "mpl.rcParams['axes.labelweight'] = 'medium'\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[hex_indigo, hex_salmon, hex_maroon])\n",
    "mpl.rcParams[\"figure.titlesize\"] = 'large'\n",
    "mpl.rcParams[\"figure.titleweight\"] = 'semibold'\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, Ridge, ElasticNet, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from entsoe import EntsoePandasClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multivariate multi-step encoder-decoder lstm\n",
    "# from math import sqrt\n",
    "# from numpy import split\n",
    "# from numpy import array\n",
    "# from pandas import read_csv\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from matplotlib import pyplot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import RepeatVector\n",
    "# from keras.layers import TimeDistributed\n",
    "\n",
    "# # load all data\n",
    "# dataset = read_csv('household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
    "\n",
    "# # mark all missing values\n",
    "# dataset.replace('?', 'nan', inplace=True)\n",
    "# # make dataset numeric\n",
    "# dataset = dataset.astype('float32')\n",
    "\n",
    "# # fill missing values with a value at the same time one day ago\n",
    "# def fill_missing(values):\n",
    "# \tone_day = 60 * 24\n",
    "# \tfor row in range(values.shape[0]):\n",
    "# \t\tfor col in range(values.shape[1]):\n",
    "# \t\t\tif isnan(values[row, col]):\n",
    "# \t\t\t\tvalues[row, col] = values[row - one_day, col]\n",
    "\n",
    "# # fill missing\n",
    "# fill_missing(dataset.values)\n",
    "\n",
    "# # add a column for for the remainder of sub metering\n",
    "# values = dataset.values\n",
    "# dataset['sub_metering_4'] = (values[:,0] * 1000 / 60) - (values[:,4] + values[:,5] + values[:,6])\n",
    "\n",
    "# # save updated dataset\n",
    "# dataset.to_csv('household_power_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multivariate multi-step encoder-decoder lstm\n",
    "# from math import sqrt\n",
    "# from numpy import split\n",
    "# from numpy import array\n",
    "# from pandas import read_csv\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from matplotlib import pyplot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import Flatten\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import RepeatVector\n",
    "# from keras.layers import TimeDistributed\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # split a univariate dataset into train/test sets\n",
    "# def split_dataset(data):\n",
    "# \t# split into standard weeks\n",
    "# \ttrain, test = data[1:-328], data[-328:-6]\n",
    "# \t# restructure into windows of weekly data\n",
    "# \ttrain = array(split(train, len(train)/7))\n",
    "# \ttest = array(split(test, len(test)/7))\n",
    "# \treturn train, test\n",
    "\n",
    "# # evaluate one or more weekly forecasts against expected values\n",
    "# def evaluate_forecasts(actual, predicted):\n",
    "# \tscores = list()\n",
    "# \t# calculate an RMSE score for each day\n",
    "# \tfor i in range(actual.shape[1]):\n",
    "# \t\t# calculate mse\n",
    "# \t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "# \t\t# calculate rmse\n",
    "# \t\trmse = sqrt(mse)\n",
    "# \t\t# store\n",
    "# \t\tscores.append(rmse)\n",
    "# \t# calculate overall RMSE\n",
    "# \ts = 0\n",
    "# \tfor row in range(actual.shape[0]):\n",
    "# \t\tfor col in range(actual.shape[1]):\n",
    "# \t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "# \tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "# \treturn score, scores\n",
    "\n",
    "# # summarize scores\n",
    "# def summarize_scores(name, score, scores):\n",
    "# \ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "# \tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# # convert history into inputs and outputs\n",
    "# def to_supervised(train, n_input, n_out=7):\n",
    "# \t# flatten data\n",
    "# \tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "# \tX, y = list(), list()\n",
    "# \tin_start = 0\n",
    "# \t# step over the entire history one time step at a time\n",
    "# \tfor _ in range(len(data)):\n",
    "# \t\t# define the end of the input sequence\n",
    "# \t\tin_end = in_start + n_input\n",
    "# \t\tout_end = in_end + n_out\n",
    "# \t\t# ensure we have enough data for this instance\n",
    "# \t\tif out_end <= len(data):\n",
    "# \t\t\tX.append(data[in_start:in_end, :])\n",
    "# \t\t\ty.append(data[in_end:out_end, 0])\n",
    "# \t\t# move along one time step\n",
    "# \t\tin_start += 1\n",
    "# \treturn array(X), array(y)\n",
    "\n",
    "# # train the model\n",
    "# def build_model(train, n_input):\n",
    "# \t# prepare data\n",
    "# \ttrain_x, train_y = to_supervised(train, n_input)\n",
    "# \t# define parameters\n",
    "# \tverbose, epochs, batch_size = 5, 2, 16\n",
    "# \tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "# \t# reshape output into [samples, timesteps, features]\n",
    "# \ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "# \t# define model\n",
    "# \tmodel = Sequential()\n",
    "# \tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "# \tmodel.add(RepeatVector(n_outputs))\n",
    "# \tmodel.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "# \tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "# \tmodel.add(TimeDistributed(Dense(1)))\n",
    "# \tmodel.compile(loss='mse', optimizer='adam')\n",
    "# \t# fit network\n",
    "# \tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# \treturn model\n",
    "\n",
    "# # make a forecast\n",
    "# def forecast(model, history, n_input):\n",
    "# \t# flatten data\n",
    "# \tdata = array(history)\n",
    "# \tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "# \t# retrieve last observations for input data\n",
    "# \tinput_x = data[-n_input:, :]\n",
    "# \t# reshape into [1, n_input, n]\n",
    "# \tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "# \t# forecast the next week\n",
    "# \tyhat = model.predict(input_x, verbose=0)\n",
    "# \t# we only want the vector forecast\n",
    "# \tyhat = yhat[0]\n",
    "# \treturn yhat\n",
    "\n",
    "# # evaluate a single model\n",
    "# def evaluate_model(train, test, n_input):\n",
    "# \t# fit model\n",
    "# \tmodel = build_model(train, n_input)\n",
    "# \t# history is a list of weekly data\n",
    "# \thistory = [x for x in train]\n",
    "# \t# walk-forward validation over each week\n",
    "# \tpredictions = list()\n",
    "# \tfor i in range(len(test)):\n",
    "# \t\t# predict the week\n",
    "# \t\tyhat_sequence = forecast(model, history, n_input)\n",
    "# \t\t# store the predictions\n",
    "# \t\tpredictions.append(yhat_sequence)\n",
    "# \t\t# get real observation and add to history for predicting the next week\n",
    "# \t\thistory.append(test[i, :])\n",
    "# \t# evaluate predictions days for each week\n",
    "# \tpredictions = array(predictions)\n",
    "# \tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "# \treturn score, scores, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate multi-step encoder-decoder lstm\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "\t# split into standard weeks\n",
    "\ttrain, test = data[data.index.year < 2018], data[data.index.year == 2018]\n",
    "\t# restructure into windows of weekly data\n",
    "\t# train = array(split(train, len(train)/7))\n",
    "\t# test = array(split(test, len(test)/7))\n",
    "\treturn train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=7):\n",
    "\t# flatten data\n",
    "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "\tX, y = list(), list()\n",
    "\tin_start = 0\n",
    "\t# step over the entire history one time step at a time\n",
    "\tfor _ in range(len(data)):\n",
    "\t\t# define the end of the input sequence\n",
    "\t\tin_end = in_start + n_input\n",
    "\t\tout_end = in_end + n_out\n",
    "\t\t# ensure we have enough data for this instance\n",
    "\t\tif out_end <= len(data):\n",
    "\t\t\tX.append(data[in_start:in_end, :])\n",
    "\t\t\ty.append(data[in_end:out_end, 0])\n",
    "\t\t# move along one time step\n",
    "\t\tin_start += 1\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# train the model\n",
    "def build_model(train, n_input):\n",
    "\t# prepare data\n",
    "\ttrain_x, train_y = to_supervised(train, n_input)\n",
    "\t# define parameters\n",
    "\tverbose, epochs, batch_size = 5, 2, 16\n",
    "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\t# reshape output into [samples, timesteps, features]\n",
    "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "\tmodel.add(RepeatVector(n_outputs))\n",
    "\tmodel.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "\tmodel.add(TimeDistributed(Dense(1)))\n",
    "\tmodel.compile(loss='mse', optimizer='adam')\n",
    "\t# fit network\n",
    "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\treturn model\n",
    "\n",
    "# make a forecast\n",
    "def forecast(model, history, n_input):\n",
    "\t# flatten data\n",
    "\tdata = array(history)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, :]\n",
    "\t# reshape into [1, n_input, n]\n",
    "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "\t# forecast the next week\n",
    "\tyhat = model.predict(input_x, verbose=0)\n",
    "\t# we only want the vector forecast\n",
    "\tyhat = yhat[0]\n",
    "\treturn yhat\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_input):\n",
    "\t# fit model\n",
    "\tmodel = build_model(train, n_input)\n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = forecast(model, history, n_input)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week\n",
    "\t\thistory.append(test[i, :])\n",
    "\t# evaluate predictions days for each week\n",
    "\tpredictions = array(predictions)\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # load the new file\n",
    "# # dataset = read_csv('household_power_consumption_days.csv', header=0, infer_datetime_format=True, parse_dates=['datetime'], index_col=['datetime'])\n",
    "# dataset = features = pd.read_pickle(f\"./features.pkl\")\n",
    "\n",
    "# # split into train and test\n",
    "# train, test = split_dataset(dataset.values)\n",
    "# # evaluate model and get scores\n",
    "# n_input = 14\n",
    "# score, scores = evaluate_model(train, test, n_input)\n",
    "# # summarize scores\n",
    "# summarize_scores('lstm', score, scores)\n",
    "# # plot scores\n",
    "# days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "# pyplot.plot(days, scores, marker='o', label='lstm')\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = features = pd.read_pickle(f\"./features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 7\n",
    "score, scores, model = evaluate_model(train, test, n_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pred2 = np.hstack(prediction[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# Pre\n",
    "\n",
    "actual_pred = actual_pred2\n",
    "\n",
    "# actual_pred = pd.DataFrame()\n",
    "\n",
    "# actual_pred['Actual'] = features['ID3'][0:len(prediction)]\n",
    "# actual_pred['Predicted'] = prediction[:, 0]\n",
    "\n",
    "####################################################################################################\n",
    "# Plot 1\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10 ,5))\n",
    "\n",
    "ax.plot(actual_pred2)\n",
    "\n",
    "####################################################################################################\n",
    "# # Plot 2\n",
    "\n",
    "# x, y = actual_pred.index, actual_pred['Predicted']\n",
    "\n",
    "# ax.plot(x, y, alpha = 0.5)\n",
    "\n",
    "# plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize scores\n",
    "summarize_scores('lstm', score, scores)\n",
    "# plot scores\n",
    "days = ['sun', 'mon', 'tue', 'wed', 'thr', 'fri', 'sat']\n",
    "pyplot.plot(days, scores, marker='o', label='lstm')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}