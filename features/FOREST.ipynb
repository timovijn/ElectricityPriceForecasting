{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load necessary packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "hex_salmon = '#F68F83'\n",
    "hex_gold = '#BC9661'\n",
    "hex_indigo = '#2D2E5F'\n",
    "hex_maroon = '#8C4750'\n",
    "hex_white = '#FAFAFA'\n",
    "hex_blue = '#7EB5D2'\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as dates\n",
    "mpl.rcParams['font.family'] = 'SF Compact Text'\n",
    "mpl.rcParams['font.weight'] = 'medium'\n",
    "mpl.rcParams['axes.titleweight'] = 'semibold'\n",
    "mpl.rcParams['axes.labelweight'] = 'medium'\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=[hex_indigo, hex_salmon, hex_maroon])\n",
    "mpl.rcParams[\"figure.titlesize\"] = 'large'\n",
    "mpl.rcParams[\"figure.titleweight\"] = 'semibold'\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "source": [
    "# Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "importing Jupyter notebook from data.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from data import create_features\n",
    "\n",
    "years = [2018]\n",
    "\n",
    "lags_ID = range(-4, -169, -1)\n",
    "lags_DA = [i for i in range(5, -6, -1) if i not in [0]]\n",
    "lags_VOL = [i for i in range(-4, -25, -1) if i not in [0]]\n",
    "\n",
    "ID, DA, features = create_features(years, lags_ID, lags_DA, lags_VOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                           ID3  Volume\n",
       "Instrument                            \n",
       "2018-01-01 00:00:00  14.586875   221.4\n",
       "2018-01-01 01:00:00  12.990924   669.7\n",
       "2018-01-01 02:00:00  22.150235   752.0\n",
       "2018-01-01 03:00:00  21.917514   460.2\n",
       "2018-01-01 04:00:00  21.621781   453.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID3</th>\n      <th>Volume</th>\n    </tr>\n    <tr>\n      <th>Instrument</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-01 00:00:00</th>\n      <td>14.586875</td>\n      <td>221.4</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 01:00:00</th>\n      <td>12.990924</td>\n      <td>669.7</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 02:00:00</th>\n      <td>22.150235</td>\n      <td>752.0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 03:00:00</th>\n      <td>21.917514</td>\n      <td>460.2</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 04:00:00</th>\n      <td>21.621781</td>\n      <td>453.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "ID.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       MCP\n",
       "Instrument                \n",
       "2018-01-01 00:00:00  27.20\n",
       "2018-01-01 01:00:00  27.30\n",
       "2018-01-01 02:00:00  30.10\n",
       "2018-01-01 03:00:00  20.87\n",
       "2018-01-01 04:00:00  25.56"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MCP</th>\n    </tr>\n    <tr>\n      <th>Instrument</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-01 00:00:00</th>\n      <td>27.20</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 01:00:00</th>\n      <td>27.30</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 02:00:00</th>\n      <td>30.10</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 03:00:00</th>\n      <td>20.87</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 04:00:00</th>\n      <td>25.56</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "DA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                 ID3     VOL    MCP      Load  Load forecast  \\\n",
       "2018-01-01 05:00:00+00:00  22.352647   490.3  25.58   9768.25       11085.25   \n",
       "2018-01-01 06:00:00+00:00  23.071457   527.6  25.81  10069.75       12266.50   \n",
       "2018-01-01 07:00:00+00:00  24.345686   507.7  29.90  10408.75       14147.50   \n",
       "2018-01-01 08:00:00+00:00  25.257541  1032.5  26.33  10693.25       15932.50   \n",
       "2018-01-01 09:00:00+00:00  25.114449   771.8  26.38  11050.25       16809.75   \n",
       "\n",
       "                               LFE   ID3 (-4)   ID3 (-5)   ID3 (-6)  \\\n",
       "2018-01-01 05:00:00+00:00  1317.00  25.114449  24.868167  25.978476   \n",
       "2018-01-01 06:00:00+00:00  2196.75  24.868167  25.978476  26.555409   \n",
       "2018-01-01 07:00:00+00:00  3738.75  25.978476  26.555409  28.621735   \n",
       "2018-01-01 08:00:00+00:00  5239.25  26.555409  28.621735  29.089427   \n",
       "2018-01-01 09:00:00+00:00  5759.50  28.621735  29.089427  35.102530   \n",
       "\n",
       "                            ID3 (-7)  ...  HOD 14  HOD 15  HOD 16  HOD 17  \\\n",
       "2018-01-01 05:00:00+00:00  26.555409  ...       0       0       0       0   \n",
       "2018-01-01 06:00:00+00:00  28.621735  ...       0       0       0       0   \n",
       "2018-01-01 07:00:00+00:00  29.089427  ...       0       0       0       0   \n",
       "2018-01-01 08:00:00+00:00  35.102530  ...       0       0       0       0   \n",
       "2018-01-01 09:00:00+00:00  41.704858  ...       0       0       0       0   \n",
       "\n",
       "                           HOD 18  HOD 19  HOD 20  HOD 21  HOD 22  HOD 23  \n",
       "2018-01-01 05:00:00+00:00       0       0       0       0       0       0  \n",
       "2018-01-01 06:00:00+00:00       0       0       0       0       0       0  \n",
       "2018-01-01 07:00:00+00:00       0       0       0       0       0       0  \n",
       "2018-01-01 08:00:00+00:00       0       0       0       0       0       0  \n",
       "2018-01-01 09:00:00+00:00       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 237 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID3</th>\n      <th>VOL</th>\n      <th>MCP</th>\n      <th>Load</th>\n      <th>Load forecast</th>\n      <th>LFE</th>\n      <th>ID3 (-4)</th>\n      <th>ID3 (-5)</th>\n      <th>ID3 (-6)</th>\n      <th>ID3 (-7)</th>\n      <th>...</th>\n      <th>HOD 14</th>\n      <th>HOD 15</th>\n      <th>HOD 16</th>\n      <th>HOD 17</th>\n      <th>HOD 18</th>\n      <th>HOD 19</th>\n      <th>HOD 20</th>\n      <th>HOD 21</th>\n      <th>HOD 22</th>\n      <th>HOD 23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-01 05:00:00+00:00</th>\n      <td>22.352647</td>\n      <td>490.3</td>\n      <td>25.58</td>\n      <td>9768.25</td>\n      <td>11085.25</td>\n      <td>1317.00</td>\n      <td>25.114449</td>\n      <td>24.868167</td>\n      <td>25.978476</td>\n      <td>26.555409</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 06:00:00+00:00</th>\n      <td>23.071457</td>\n      <td>527.6</td>\n      <td>25.81</td>\n      <td>10069.75</td>\n      <td>12266.50</td>\n      <td>2196.75</td>\n      <td>24.868167</td>\n      <td>25.978476</td>\n      <td>26.555409</td>\n      <td>28.621735</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 07:00:00+00:00</th>\n      <td>24.345686</td>\n      <td>507.7</td>\n      <td>29.90</td>\n      <td>10408.75</td>\n      <td>14147.50</td>\n      <td>3738.75</td>\n      <td>25.978476</td>\n      <td>26.555409</td>\n      <td>28.621735</td>\n      <td>29.089427</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 08:00:00+00:00</th>\n      <td>25.257541</td>\n      <td>1032.5</td>\n      <td>26.33</td>\n      <td>10693.25</td>\n      <td>15932.50</td>\n      <td>5239.25</td>\n      <td>26.555409</td>\n      <td>28.621735</td>\n      <td>29.089427</td>\n      <td>35.102530</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 09:00:00+00:00</th>\n      <td>25.114449</td>\n      <td>771.8</td>\n      <td>26.38</td>\n      <td>11050.25</td>\n      <td>16809.75</td>\n      <td>5759.50</td>\n      <td>28.621735</td>\n      <td>29.089427</td>\n      <td>35.102530</td>\n      <td>41.704858</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 237 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "features.head(5)"
   ]
  },
  {
   "source": [
    "# Separate train and test sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((5468, 235), (2344, 235))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features.drop(labels=['ID3', 'Load forecast'], axis=1),\n",
    "    features['ID3'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0,\n",
    "    shuffle = True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fbb079a6f7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msel_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# this command let's me visualise those features that were selected.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/sklearn/feature_selection/_from_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \"Since 'prefit=True', call transform directly\")\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    387\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                         indices=indices)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    888\u001b[0m         \"\"\"\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/timo/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# we fit Random Forests and select features in 2 lines of code\n",
    "\n",
    "# first I specify the Random Forest instance and its parameters\n",
    "\n",
    "# Then I use the selectFromModel class from sklearn\n",
    "# to automatically select the features\n",
    "\n",
    "# SelectFrom model will select those features which importance\n",
    "# is greater than the mean importance of all the features\n",
    "# by default, but you can alter this threshold if you want to\n",
    "\n",
    "# Encode\n",
    "lab_enc = LabelEncoder()\n",
    "y_train = lab_enc.fit_transform(y_train)\n",
    "\n",
    "sel_ = SelectFromModel(RandomForestClassifier(n_estimators=10, random_state=10))\n",
    "\n",
    "sel_.fit(X_train, y_train)\n",
    "\n",
    "# this command let's me visualise those features that were selected.\n",
    "\n",
    "# sklearn will select those features which importance values\n",
    "# are greater than the mean of all the coefficients.\n",
    "\n",
    "sel_.get_support()\n",
    "\n",
    "# Summarize\n",
    "print('MSE: %.3f' % sel_.best_score_)\n",
    "print('Config: %s' % sel_.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unscaled = X_train\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train_unscaled)"
   ]
  },
  {
   "source": [
    "# Random forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Encode\n",
    "lab_enc = LabelEncoder()\n",
    "y_train = lab_enc.fit_transform(y_train)\n",
    "\n",
    "# Define model\n",
    "model = RandomForestClassifier()\n",
    "model_type = f'{model}'\n",
    "\n",
    "# Define model evaluation method\n",
    "cv = RepeatedKFold(\n",
    "    n_splits = n_folds,\n",
    "    n_repeats = 1,\n",
    "    random_state = 10)\n",
    "\n",
    "# Define grid\n",
    "grid = { \n",
    "    'n_estimators': [10],\n",
    "    # 'max_features': ['auto'],\n",
    "    # 'max_depth' : [5],\n",
    "    # 'criterion' :['gini']\n",
    "}\n",
    "\n",
    "# Define search\n",
    "search = GridSearchCV(\n",
    "    model,\n",
    "    grid,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    cv = cv,\n",
    "    n_jobs = -1)\n",
    "\n",
    "# Perform the search\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "# Summarize\n",
    "print('MSE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in zip(feat_labels, results.feature_importances_):\n",
    "#     print(feature)\n",
    "\n",
    "COEFS = pd.DataFrame()\n",
    "\n",
    "COEFS['Coefficients'] = results.best_estimator_.feature_importances_\n",
    "\n",
    "COEFS.index = X_train_unscaled.columns.values\n",
    "\n",
    "x = COEFS.index\n",
    "y = COEFS['Coefficients']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (len(x)/4, 5))\n",
    "q = ax.bar(height = y, x = x)\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "ax.set_title(rf'Coefficients from {model_type}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from time import time\n",
    "\n",
    "n_features = 10\n",
    "\n",
    "threshold = np.sort(abs(COEFS['Coefficients']))[-n_features]\n",
    "\n",
    "print(), print(f'Threshold: {threshold}'), print()\n",
    "\n",
    "sel_ = SelectFromModel(results.best_estimator_, threshold = threshold, prefit = True)\n",
    "\n",
    "for i in sel_.get_support(indices = True):\n",
    "    print(COEFS.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COEFS_sel = COEFS[sel_.get_support()].reindex(COEFS[sel_.get_support()]['Coefficients'].abs().sort_values(ascending = False).index)\n",
    "\n",
    "x = COEFS_sel.index\n",
    "y = COEFS_sel['Coefficients']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (len(x)/4, 5))\n",
    "q = ax.bar(height = y, x = x, width = 0.8)\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "ax.set_title(rf'Non-zero features (sorted by coefficient magnitude) from {model_type}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COEFS_sort = COEFS.reindex(COEFS['Coefficients'].abs().sort_values(ascending = False).index)\n",
    "\n",
    "x = COEFS_sort.index\n",
    "y = COEFS_sort['Coefficients']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (len(x)/4, 5))\n",
    "q = ax.bar(height = y, x = x, width = 0.8)\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "ax.set_title(rf'Coefficients from {model_type}')\n",
    "\n",
    "ax.axhspan(threshold, -threshold, facecolor = hex_salmon, alpha = 0.1)\n",
    "\n",
    "# for t in [threshold, -threshold]:\n",
    "#     ax.axhline(t, linewidth = 1, linestyle = '-', color = hex_indigo, alpha = 0.5, label = rf'$\\alpha$: {round(alpha, 4)}')\n",
    "\n",
    "for item in q[0:n_features]:\n",
    "     item.set_color(hex_salmon)"
   ]
  },
  {
   "source": [
    "# Visualise"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[sel_.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected = X_train.columns[(sel_.get_support())]\n",
    "\n",
    "len(features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(sel_.estimator_.feature_importances_.ravel()).hist(bins=20)\n",
    "plt.xlabel('Feature importance')\n",
    "plt.ylabel('Number of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(), print(colored('Summary:', 'blue')), print()\n",
    "\n",
    "print(f'Total features: {X_train.shape[1]}')\n",
    "print(f'Selected features: {len(X_train.columns[(sel_.get_support())])}')\n",
    "print(f'features with importance greater than the mean importance of all features: {np.sum(sel_.estimator_.feature_importances_ > sel_.estimator_.feature_importances_.mean())}')\n",
    "\n",
    "print(), print(colored('Selected columns:', 'blue')), print()\n",
    "print(X_train.columns[sel_.get_support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features.drop(labels=['ID3', 'Load forecast'], axis=1),\n",
    "    features['ID3'],\n",
    "    test_size = 0.3,\n",
    "    random_state = 0,\n",
    "    shuffle = True)\n",
    "\n",
    "X_train_unscaled = X_train\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train_unscaled)\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feat_labels, clf.feature_importances_):\n",
    "    print(feature)\n",
    "    \n",
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.15\n",
    "sfm = SelectFromModel(clf, threshold=0.15)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)\n",
    "\n",
    "# Print the names of the most important features\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])\n",
    "    \n",
    "# Transform the data to create a new dataset containing only the most important features\n",
    "# Note: We have to apply the transform to both the training X and test X data.\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)\n",
    "\n",
    "# Create a new random forest classifier for the most important features\n",
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the new classifier on the new dataset containing the most important features\n",
    "clf_important.fit(X_important_train, y_train)\n",
    "\n",
    "\n",
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# View The Accuracy Of Our Full Feature (4 Features) Model\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "#0.93333333333333335\n",
    "\n",
    "# Apply The Full Featured Classifier To The Test Data\n",
    "y_important_pred = clf_important.predict(X_important_test)\n",
    "\n",
    "# View The Accuracy Of Our Limited Feature (2 Features) Model\n",
    "accuracy_score(y_test, y_important_pred)\n",
    "\n",
    "#0.8833333333333333"
   ]
  }
 ]
}